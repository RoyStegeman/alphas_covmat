{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c3594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from validphys.loader import FallbackLoader as Loader\n",
    "from validphys.api import API\n",
    "from collections import defaultdict\n",
    "from scipy.stats import norm\n",
    "from validphys.plotutils import kde_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1db218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_names = [f\"240427-rs-alphas_0{n}\" for n in range(1140,1250+1,10)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb1ad89",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = Loader()\n",
    "fits = [l.check_fit(f) for f in fit_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ac6692",
   "metadata": {},
   "source": [
    "# Correlated Replica Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32685b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "as_fits = defaultdict(list)\n",
    "for f in fits:\n",
    "    th = f.as_input()[\"theory\"][\"theoryid\"]\n",
    "    alpha = float(API.theory_info_table(theory_db_id = th).loc[\"alphas\"])\n",
    "    as_fits[alpha].append(f)\n",
    "as_fits = dict(as_fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd0980b",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = {f: API.fitted_replica_indexes(pdf=f.name) for f in fits}\n",
    "replica_data = {f: API.replica_data(fit=f.name) for f in fits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1644bac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure(replica_data):\n",
    "    return replica_data.training*3 + replica_data.validation*1\n",
    "    # return replica_data.chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375353b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_values = {}\n",
    "for alpha, flist in as_fits.items():\n",
    "    series = []\n",
    "    for f in flist:\n",
    "        s = [measure(d) for d in replica_data[f]]\n",
    "        series.append(pd.Series(s, index=indexes[f]))\n",
    "    min_values[alpha] = pd.DataFrame(series).min()\n",
    "data = pd.DataFrame(min_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec6db68",
   "metadata": {},
   "outputs": [],
   "source": [
    "mins = {}\n",
    "for ind, row in data.iterrows():\n",
    "    a, b, c = np.polyfit(data.columns, row, 2)\n",
    "    if not np.isnan(b): # NaN if not all replicas passed postfit\n",
    "        mins[ind] = -b / 2 / a\n",
    "    # mins[ind] = data.columns[np.where(row==row.min())][0]\n",
    "\n",
    "mins = pd.Series(mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7909e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mins.describe(percentiles=[0.16,0.84]))\n",
    "print(\"\")\n",
    "print(f\"cv±std = {mins.mean():.5f} ± {mins.std():.5f} \")\n",
    "print(f\"1std interval:  {mins.mean()-mins.std():.5f} to {mins.mean()+mins.std():.5f} \")\n",
    "print(f\"68% c.i:        {mins.describe(percentiles=[0.16,0.84])[4]:.5f} to {mins.describe(percentiles=[0.16,0.84])[6]:.5f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6c37c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "kde_plot(mins,ax=ax)\n",
    "central = (mins.describe(percentiles=[0.16,0.84])[6] + mins.describe(percentiles=[0.16,0.84])[4])/2\n",
    "unc = (mins.describe(percentiles=[0.16,0.84])[6] - mins.describe(percentiles=[0.16,0.84])[4])/2\n",
    "ax.set_title(f\"68% c.i: {central:.5f}  ± {unc:.5f}  -- MHOU\")\n",
    "ax.set_xlim(0.118,0.13)\n",
    "ax.set_xlabel(r\"$\\alpha_s$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6433e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mins,bins=data.columns-0.0005,edgecolor='black',density=True)\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "# p = np.exp(-((x-mins.mean())/mins.std())**2/2)*mins.size/np.sqrt(2*np.pi)\n",
    "p = norm.pdf(x, mins.mean(), mins.std())\n",
    "plt.plot(x,p,'k',label=f\"{mins.mean():.5f} +/- {mins.std():.5f}\")\n",
    "plt.yticks([])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a5fa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data.columns, np.array(data.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3439b7b8",
   "metadata": {},
   "source": [
    "# Experimental/naive method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7eb462",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_dict = dict(\n",
    "    fit=fit_names[0],\n",
    "    dataset_inputs={\"from_\": \"fit\"},\n",
    "    pdf={\"from_\": \"fit\"},\n",
    "    use_cuts=\"fromfit\",\n",
    "    theory={\"from_\": \"fit\"},\n",
    "    theoryid={\"from_\": \"theory\"},\n",
    ")\n",
    "\n",
    "# Experimental covariance matrix\n",
    "# C = API.groups_covmat(\n",
    "#     use_t0 = False,\n",
    "#     **naive_dict\n",
    "# )\n",
    "\n",
    "# t0 covariance matrix (th ecorrect one, see bottom of page 15 of https://arxiv.org/pdf/1802.03398)\n",
    "C = API.groups_covmat(\n",
    "    fit=fit_names[0],\n",
    "    use_t0 = True,\n",
    "    use_cuts=\"fromfit\",\n",
    "    datacuts={\"from_\": \"fit\"},\n",
    "    t0pdfset={\"from_\": \"datacuts\"},\n",
    "    dataset_inputs={\"from_\": \"fit\"},\n",
    "    theoryid=API.fit(fit=fit_names[0]).as_input()[\"theory\"][\"t0theoryid\"],\n",
    ")\n",
    "\n",
    "chi2_values = []\n",
    "alphas_values = []\n",
    "for fitname in fit_names:\n",
    "    naive_dict[\"fit\"] = fitname\n",
    "    central_preds_and_data = API.group_result_central_table_no_table(**naive_dict)\n",
    "\n",
    "    theory_db_id = API.fit(fit=fitname).as_input()[\"theory\"][\"theoryid\"]\n",
    "    alphas_values.append(float(API.theory_info_table(theory_db_id = theory_db_id).loc[\"alphas\"]))\n",
    "\n",
    "    # compute chi2\n",
    "    diff = central_preds_and_data.theory_central - central_preds_and_data.data_central\n",
    "    chi2_values.append(diff @ np.linalg.inv(C) @ diff / diff.size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acfcb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = np.polyfit(alphas_values, chi2_values, 2)\n",
    "\n",
    "central = -b / 2 / a\n",
    "ndata = C.shape[0]\n",
    "unc = np.sqrt(1/a/ndata)\n",
    "\n",
    "plt.scatter(alphas_values, chi2_values, color=\"blue\" )\n",
    "xgrid = np.linspace(min(alphas_values),max(alphas_values))\n",
    "plt.plot(xgrid, [a*x*x + b*x + c for x in xgrid], color=\"black\", linestyle=\"--\")\n",
    "plt.title(rf\"$\\alpha_s$={central:.4f}$\\pm${unc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnpdf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "589e3134e9d89160e5ace28972e8dc0b682f48816407b59cbfdad217f6fb745b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
