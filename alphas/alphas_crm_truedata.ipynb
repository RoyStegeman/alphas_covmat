{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c3594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from validphys.loader import FallbackLoader as Loader\n",
    "from validphys.api import API\n",
    "from collections import defaultdict\n",
    "from scipy.stats import norm\n",
    "from validphys.plotutils import kde_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1db218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_names = [f\"240718-n3lo-alphas_0{n}\" for n in range(1140,1250+1,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb1ad89",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = Loader()\n",
    "fits = [l.check_fit(f) for f in fit_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ac6692",
   "metadata": {},
   "source": [
    "# Correlated Replica Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32685b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "as_fits = defaultdict(list)\n",
    "for f in fits:\n",
    "    th = f.as_input()[\"theory\"][\"theoryid\"]\n",
    "    alpha = API.theory_info_table(theory_db_id = th).loc[\"alphas\"].iloc[0]\n",
    "    as_fits[alpha].append(f)\n",
    "as_fits = dict(as_fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd0980b",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = {f: API.fitted_replica_indexes(pdf=f.name) for f in fits}\n",
    "replica_data = {f: API.replica_data(fit=f.name) for f in fits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1644bac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure(replica_data):\n",
    "    return replica_data.training*3 + replica_data.validation*1\n",
    "    # return replica_data.chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375353b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_values = {}\n",
    "for alpha, flist in as_fits.items():\n",
    "    series = []\n",
    "    for f in flist:\n",
    "        s = [measure(d) for d in replica_data[f]]\n",
    "        series.append(pd.Series(s, index=indexes[f]))\n",
    "    min_values[alpha] = pd.DataFrame(series).min()\n",
    "data = pd.DataFrame(min_values).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec6db68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # quadracit polynomial\n",
    "# mins = {}\n",
    "# for ind, row in data.iterrows():\n",
    "#     p2, p1, p0 = np.polyfit(data.columns, row, 2)\n",
    "#     if not np.isnan(p1): # NaN if not all replicas passed postfit\n",
    "#         mins[ind] = -p1 / 2 / p2\n",
    "#     # mins[ind] = data.columns[np.where(row==row.min())][0]\n",
    "\n",
    "# mins = pd.Series(mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0acc403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cubic polynomial\n",
    "mins = {}\n",
    "for ind, row in data.iterrows():\n",
    "    coefficients = np.polyfit(data.columns, row, 3)\n",
    "    if not np.isnan(coefficients).all():\n",
    "        polynomial = np.poly1d(coefficients)\n",
    "        derivative = polynomial.deriv()\n",
    "        critical_points = np.roots(derivative)\n",
    "        as_vals = data.keys()\n",
    "        valid_critical_points = [point for point in critical_points if min(as_vals) <= point <= max(as_vals)]\n",
    "        second_derivative = polynomial.deriv(2)\n",
    "        min_points = []\n",
    "        for point in valid_critical_points:\n",
    "            if second_derivative(point) > 0:  # Minimum if the second derivative is positive\n",
    "                min_points.append(point)\n",
    "        min_values = [polynomial(point) for point in min_points]\n",
    "        min_index = min_values.index(min(min_values))\n",
    "        min_x = min_points[min_index]\n",
    "        min_y = min_values[min_index]\n",
    "        mins[ind] = min_x\n",
    "mins = pd.Series(mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0dffcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # quartic polynomial\n",
    "# mins = {}\n",
    "# alphas_vals = data.keys()\n",
    "# for ind, row in data.iterrows():\n",
    "#     coefficients = np.polyfit(data.columns, row, 4)\n",
    "#     p4, p3, p2, p1, p0 = coefficients\n",
    "#     if not np.isnan(p1):\n",
    "\n",
    "#         # Define the polynomial\n",
    "#         def poly(x):\n",
    "#             return p4*x**4 + p3*x**3 + p2*x**2 + p1*x + p0\n",
    "\n",
    "#         # Define the first derivative of the polynomial\n",
    "#         def poly_derivative(x):\n",
    "#             return 4*p4*x**3 + 3*p3*x**2 + 2*p2*x + p1\n",
    "\n",
    "#         # Define the second derivative of the polynomial\n",
    "#         def poly_second_derivative(x):\n",
    "#             return 12*p4*x**2 + 6*p3*x + 2*p2\n",
    "\n",
    "#         # Find where the first derivative vanishes\n",
    "#         critical_points = np.roots([4*p4, 3*p3, 2*p2, p1])\n",
    "\n",
    "#         # Evaluate the polynomial and second derivative at the critical points\n",
    "#         min_value = float('inf')\n",
    "#         min_point = None\n",
    "\n",
    "#         # Check the polynomial values at the interval endpoints (smallest and largest values of x)\n",
    "#         interval_start = min(alphas_vals)\n",
    "#         interval_end = max(alphas_vals)\n",
    "\n",
    "#         for point in critical_points:\n",
    "#             if np.isreal(point) and point >= interval_start and point <= interval_end:  # Consider only real roots in the alphas domain\n",
    "#                 point = np.real(point)\n",
    "#                 if poly_second_derivative(point) > 0:  # Check if it is a minimum\n",
    "#                     value = poly(point)\n",
    "#                     if value < min_value:\n",
    "#                         min_value = value\n",
    "#                         min_point = point\n",
    "\n",
    "\n",
    "#         start_value = poly(interval_start)\n",
    "#         end_value = poly(interval_end)\n",
    "\n",
    "#         # Compare with the minimum found at critical points\n",
    "#         if start_value < min_value:\n",
    "#             min_value = start_value\n",
    "#             min_point = interval_start\n",
    "\n",
    "#         if end_value < min_value:\n",
    "#             min_value = end_value\n",
    "#             min_point = interval_end\n",
    "\n",
    "#         mins[ind] = min_point\n",
    "# mins = pd.Series(mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7909e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mins.describe(percentiles=[0.16,0.84]))\n",
    "print(\"\")\n",
    "print(f\"cv±std = {mins.mean():.4f} ± {mins.std():.4f} \")\n",
    "print(f\"1std interval:  {mins.mean()-mins.std():.5f} to {mins.mean()+mins.std():.5f} \")\n",
    "print(f\"68% c.i:        {mins.describe(percentiles=[0.16,0.84])[4]:.5f} to {mins.describe(percentiles=[0.16,0.84])[6]:.5f} \")\n",
    "print(f\"68% c.i:        {(mins.describe(percentiles=[0.16,0.84])[4] + mins.describe(percentiles=[0.16,0.84])[6])/2:.4f} ± {(mins.describe(percentiles=[0.16,0.84])[6] - mins.describe(percentiles=[0.16,0.84])[4])/2:.4f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6c37c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "kde_plot(mins,ax=ax)\n",
    "central = (mins.describe(percentiles=[0.16,0.84])[6] + mins.describe(percentiles=[0.16,0.84])[4])/2\n",
    "unc = (mins.describe(percentiles=[0.16,0.84])[6] - mins.describe(percentiles=[0.16,0.84])[4])/2\n",
    "ax.set_title(f\"68% c.i: {central:.5f}  ± {unc:.5f}  -- MHOU\")\n",
    "# ax.set_xlim(0.118,0.13)\n",
    "ax.set_xlabel(r\"$\\alpha_s$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6433e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mins,bins=data.columns-0.0005,edgecolor='black',density=True)\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "# p = np.exp(-((x-mins.mean())/mins.std())**2/2)*mins.size/np.sqrt(2*np.pi)\n",
    "p = norm.pdf(x, mins.mean(), mins.std())\n",
    "plt.plot(x,p,'k',label=f\"{mins.mean():.5f} +/- {mins.std():.5f}\")\n",
    "plt.yticks([])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e99465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot parabola per replica\n",
    "\n",
    "xgrid = np.linspace(min(data.columns),max(data.columns))\n",
    "for i in range(len(data)):\n",
    "    chi2_values = data.iloc[i]\n",
    "    coefficients = np.polyfit(data.columns, chi2_values, 3)\n",
    "    plt.figure()\n",
    "    plt.plot(data.columns, chi2_values, '.')\n",
    "    plt.plot(xgrid, np.polyval(coefficients, xgrid), color=\"black\", linestyle=\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63bbdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgrid = np.linspace(min(data.columns),max(data.columns))\n",
    "chi2_values = data.iloc[186]\n",
    "coefficients = np.polyfit(data.columns, chi2_values, 4)\n",
    "plt.figure()\n",
    "plt.plot(data.columns, chi2_values, '.')\n",
    "plt.plot(xgrid, np.polyval(coefficients, xgrid), color=\"black\", linestyle=\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a5fa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data.columns, np.array(data.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3439b7b8",
   "metadata": {},
   "source": [
    "# Experimental/naive method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7eb462",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_dict = dict(\n",
    "    fit=fit_names[0],\n",
    "    dataset_inputs={\"from_\": \"fit\"},\n",
    "    pdf={\"from_\": \"fit\"},\n",
    "    use_cuts=\"fromfit\",\n",
    "    theory={\"from_\": \"fit\"},\n",
    "    theoryid={\"from_\": \"theory\"},\n",
    ")\n",
    "\n",
    "# Experimental covariance matrix\n",
    "# C = API.groups_covmat(\n",
    "#     use_t0 = False,\n",
    "#     **naive_dict\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# t0 covariance matrix (the correct one, see bottom of page 15 of https://arxiv.org/pdf/1802.03398)\n",
    "C = API.groups_covmat(\n",
    "    fit=fit_names[0],\n",
    "    use_t0 = True,\n",
    "    use_cuts=\"fromfit\",\n",
    "    datacuts={\"from_\": \"fit\"},\n",
    "    t0pdfset={\"from_\": \"datacuts\"},\n",
    "    dataset_inputs={\"from_\": \"fit\"},\n",
    "    theoryid=API.fit(fit=fit_names[0]).as_input()[\"theory\"][\"t0theoryid\"],\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5aa1538",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    stored_covmat = pd.read_csv(\n",
    "        fits[0].path / \"tables/datacuts_theory_theorycovmatconfig_theory_covmat_custom.csv\",\n",
    "        index_col=[0, 1, 2],\n",
    "        header=[0, 1, 2],\n",
    "        sep=\"\\t|,\",\n",
    "        engine=\"python\",\n",
    "    ).fillna(0)\n",
    "    storedcovmat_index = pd.MultiIndex.from_tuples(\n",
    "        [(aa, bb, np.int64(cc)) for aa, bb, cc in stored_covmat.index],\n",
    "        names=[\"group\", \"dataset\", \"id\"],\n",
    "    ).droplevel(0)  # make sure \"id\" is an integer, same as in C, and drop the group since that may differ\n",
    "    stored_covmat = pd.DataFrame(\n",
    "        stored_covmat.values, index=storedcovmat_index, columns=storedcovmat_index\n",
    "    )\n",
    "    stored_covmat = stored_covmat.reindex(C.index.droplevel(0)).T.reindex(C.index.droplevel(0))\n",
    "    t0covmat = pd.DataFrame(\n",
    "        C.values, index=C.index.droplevel(0), columns=C.index.droplevel(0)\n",
    "    )\n",
    "    invcov = np.linalg.inv(t0covmat+stored_covmat)\n",
    "except:\n",
    "    invcov = np.linalg.inv(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79943dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_values = []\n",
    "alphas_values = []\n",
    "for fitname in fit_names:\n",
    "    naive_dict[\"fit\"] = fitname\n",
    "    central_preds_and_data = API.group_result_central_table_no_table(**naive_dict)\n",
    "\n",
    "    theory_db_id = API.fit(fit=fitname).as_input()[\"theory\"][\"theoryid\"]\n",
    "    alphas_values.append(API.theory_info_table(theory_db_id = theory_db_id).loc[\"alphas\"].iloc[0])\n",
    "\n",
    "    # compute chi2\n",
    "    diff = central_preds_and_data.theory_central - central_preds_and_data.data_central\n",
    "    chi2_values.append(diff @ invcov @ diff / diff.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acfcb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = np.polyfit(alphas_values, chi2_values, 2)\n",
    "\n",
    "central = -b / 2 / a\n",
    "ndata = C.shape[0]\n",
    "unc = np.sqrt(1/a/ndata)\n",
    "\n",
    "plt.scatter(alphas_values, chi2_values, color=\"blue\" )\n",
    "xgrid = np.linspace(min(alphas_values),max(alphas_values))\n",
    "plt.plot(xgrid, [a*x*x + b*x + c for x in xgrid], color=\"black\", linestyle=\"--\")\n",
    "plt.title(rf\"$\\alpha_s$={central:.4f}$\\pm${unc:.4f}\")\n",
    "print(f\"{central:.4f} ± {unc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnpdf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "589e3134e9d89160e5ace28972e8dc0b682f48816407b59cbfdad217f6fb745b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
