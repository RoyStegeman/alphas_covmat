{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226dc610",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from validphys.api import API\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# fitname = \"240108-01-rs-ht-tcm-disonly\" # ht_coeff = 2.5\n",
    "# fitname = \"240109-01-rs-ht-tcm-disonly\" # ht_coeff = 1.0 | -0.02256 ± 0.02550\n",
    "# fitname = \"240109-02-rs-ht-tcm-disonly\" # ht_coeff = 1.0, iterated | -0.03457 ± 0.02597\n",
    "fitname = \"240109-03-rs-ht-tcm-disonly\" # ht_coeff = 2.5, iterated | 0.61057 ± 0.02822\n",
    "# fitname = \"240109-04-rs-ht-tcm-disonly\" # 240109-02-rs-ht-tcm-disonly with lowered cuts | 0.21670 ± 0.01147\n",
    "# fitname = \"240110-01-rs-ht-tcm-disonly\" # 240109-02-rs-ht-tcm-disonly with highered cuts | 0.05157 ± 0.07621"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dae95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ht_coeff = API.fit(fit=fitname).as_input()[\"theorycovmatconfig\"][\"ht_coeff\"]\n",
    "\n",
    "# dict used to produce theory predictions to construct the theory covmat as well as to produce\n",
    "# theory predictions from the fit performed using the ht covmat (i.e. the predicitons that should\n",
    "# be compared to data)\n",
    "common_dict = dict(\n",
    "    dataset_inputs={\"from_\": \"fit\"},\n",
    "    fit=fitname,\n",
    "    fits=[fitname],\n",
    "    use_cuts=\"fromfit\",\n",
    "    metadata_group=\"nnpdf31_process\",\n",
    "    theory={\"from_\": \"fit\"},\n",
    "    theoryid={\"from_\": \"theory\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d0d9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect the information (predictions + kinematics) needed for the computation of the HT covmat\n",
    "\n",
    "# Calculate theory predictions of the input PDF\n",
    "S_dict = dict(\n",
    "    theorycovmatconfig={\"from_\": \"fit\"},\n",
    "    pdf={\"from_\": \"theorycovmatconfig\"},\n",
    "    use_t0=True,\n",
    "    datacuts={\"from_\": \"fit\"},\n",
    "    t0pdfset={\"from_\": \"datacuts\"},\n",
    ")\n",
    "preds_ht_cov_construction = API.group_result_table_no_table(**(S_dict | common_dict))\n",
    "\n",
    "# collect the corresponding kinemacs\n",
    "process_info = API.combine_by_type_ht(**(S_dict | common_dict))\n",
    "kinematics = np.concatenate([v for v in process_info.data.values()]).T\n",
    "xvals = kinematics[0]\n",
    "q2vals = kinematics[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c21605b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate theory predictions of the fit with ht covmat - this will be compared to data\n",
    "preds = API.group_result_table_no_table(pdf={\"from_\": \"fit\"}, **common_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc820c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the matrix X encoding the PDF uncertainties of the predictions\n",
    "\n",
    "preds_onlyreplicas = preds.iloc[:, 2:].to_numpy()\n",
    "mean_prediction = np.mean(preds_onlyreplicas, axis=1)\n",
    "\n",
    "X = np.zeros((preds.shape[0], preds.shape[0]))\n",
    "for i in range(preds_onlyreplicas.shape[1]):\n",
    "    X += np.outer(\n",
    "        (preds_onlyreplicas[:, i] - mean_prediction), (preds_onlyreplicas[:, i] - mean_prediction)\n",
    "    )\n",
    "X *= 1 / preds_onlyreplicas.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76acc02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the delta of the theory prediction\n",
    "delta_pred = ht_coeff * (\n",
    "    preds_ht_cov_construction[\"theory_central\"] / q2vals / (1 - xvals)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800cd4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Theory covariance matrix\n",
    "S = np.outer(delta_pred, delta_pred)\n",
    "S = pd.DataFrame(S, index=delta_pred.index, columns=delta_pred.index)\n",
    "\n",
    "# Experimental covariance matrix\n",
    "C = API.groups_covmat_no_table(**common_dict)\n",
    "\n",
    "# Ensure that S anc C are ordered in the same way (in practice they already are)\n",
    "S = S.reindex(C.index).T.reindex(C.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d896cf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the central value of the pseudodata\n",
    "# this is needed to compute the distance between prediction and data\n",
    "pseudodata = API.read_pdf_pseudodata(**common_dict)\n",
    "dat_central = np.mean(\n",
    "    [i.pseudodata.reindex(preds.index.to_list()).to_numpy().flatten() for i in pseudodata],\n",
    "    axis=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b5b798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute delta_T_tilde (Eq. 3.37) and P_tilde (Eq. 3.38) of arXiv:2105.05114\n",
    "\n",
    "# The factors 1/sqrt(2) are to normalize for the fact that beta provides information about\n",
    "# theoretical uncertainties along two directions\n",
    "beta_tilde = ht_coeff * np.sqrt(1/2) * np.array([1, -1])\n",
    "S_tilde = beta_tilde @ beta_tilde\n",
    "beta = np.sqrt(1/2) * np.array([delta_pred, -delta_pred])\n",
    "S_hat = beta_tilde @ beta\n",
    "\n",
    "invcov = np.linalg.inv(C + S)\n",
    "\n",
    "delta_T_tilde = -S_hat @ invcov @ (mean_prediction - dat_central)\n",
    "# where are the X_tilde and X_hat terms in P_tilde?\n",
    "# Maybe not present because we don't have correlations between theory parameters\n",
    "P_tilde = S_hat @ invcov @ X @ invcov @ S_hat + (S_tilde - S_hat @ invcov @ S_hat)\n",
    "ht_coeff_central = 0.0\n",
    "pred = ht_coeff_central + delta_T_tilde\n",
    "unc = np.sqrt(P_tilde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50ade72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the stored covmat is equal to S we recomputed above\n",
    "fitpath = API.fit(fit=fitname).path\n",
    "try:\n",
    "    stored_covmat = pd.read_csv(\n",
    "        fitpath / \"tables/datacuts_theory_theorycovmatconfig_user_covmat.csv\",\n",
    "        sep=\"\\t\",\n",
    "        encoding=\"utf-8\",\n",
    "        index_col=2,\n",
    "        header=3,\n",
    "        skip_blank_lines=False,\n",
    "    )\n",
    "except FileNotFoundError:\n",
    "    stored_covmat = pd.read_csv(\n",
    "        fitpath / \"tables/datacuts_theory_theorycovmatconfig_theory_covmat_custom.csv\",\n",
    "        index_col=[0, 1, 2],\n",
    "        header=[0, 1, 2],\n",
    "        sep=\"\\t|,\",\n",
    "        engine=\"python\",\n",
    "    ).fillna(0)\n",
    "    storedcovmat_index = pd.MultiIndex.from_tuples(\n",
    "        [(aa, bb, np.int64(cc)) for aa, bb, cc in stored_covmat.index],\n",
    "        names=[\"group\", \"dataset\", \"id\"],\n",
    "    )\n",
    "    stored_covmat = pd.DataFrame(\n",
    "        stored_covmat.values, index=storedcovmat_index, columns=storedcovmat_index\n",
    "    )\n",
    "    stored_covmat = stored_covmat.reindex(S.index).T.reindex(S.index)\n",
    "\n",
    "# print the final result\n",
    "if np.allclose(S, stored_covmat):\n",
    "    print(rf\"Prediction for ht_coeff: {pred:.5f} ± {unc:.5f}\")\n",
    "else:\n",
    "    print(\"Reconstructed theory covmat, S, is not the same as the stored covmat!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec79a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "ax.scatter(\n",
    "    xvals,\n",
    "    q2vals,\n",
    "    marker=\".\",\n",
    "    c=stored_covmat.to_numpy().diagonal(),\n",
    "    cmap=\"viridis\",\n",
    "    norm=mcolors.LogNorm(),\n",
    ")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(r\"$x$\")\n",
    "ax.set_ylabel(r\"$Q^2$\");\n",
    "\n",
    "filterlist = []\n",
    "q2min = 10\n",
    "w2min = 45\n",
    "for i,(x,q2) in enumerate(zip(xvals, q2vals)):\n",
    "    w2 = q2*(1-x)/x\n",
    "    if q2 < q2min:\n",
    "        filterlist.append(i)\n",
    "    elif w2 < w2min:\n",
    "        filterlist.append(i)\n",
    "\n",
    "ax.scatter(\n",
    "    xvals[filterlist],\n",
    "    q2vals[filterlist],\n",
    "    marker=\".\",\n",
    "    color=\"black\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e11d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "API.plot_xq2(\n",
    "    fit=fitname,\n",
    "    dataset_inputs={\"from_\": \"fit\"},\n",
    "    use_cuts=\"fromfit\",\n",
    "    display_cuts=False,\n",
    "    marker_by=\"dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa074b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display\n",
    "pdfs = [\n",
    "    \"240109-02-rs-ht-tcm-disonly\",\n",
    "    \"240109-03-rs-ht-tcm-disonly\"\n",
    "]\n",
    "%matplotlib widget\n",
    "flavours = ['g', 'u', 'd', 'ubar' ]\n",
    "figs = API.plot_pdfs(pdfs=pdfs, Q=1.65, flavours=flavours)\n",
    "for fig, fl in figs:\n",
    "    fig.tight_layout()\n",
    "    display(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnpdf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "589e3134e9d89160e5ace28972e8dc0b682f48816407b59cbfdad217f6fb745b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
