{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "226dc610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import interpolate as scint\n",
    "from validphys.api import API\n",
    "from validphys.loader import FallbackLoader\n",
    "from validphys.theorycovariance.construction import compute_normalisation_by_experiment\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "l = FallbackLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "377309ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitname = \"240921_01_ht_preds\"\n",
    "fitname_ref = \"240807-midcuts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9d93689",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = API.fit(fit=fitname)\n",
    "fit_ref = API.fit(fit=fitname_ref)\n",
    "\n",
    "settings_dict = dict(\n",
    "    dataset_inputs={\"from_\": \"fit\"},\n",
    "    fit=fit.name,\n",
    "    use_cuts=\"fromfit\",\n",
    "    metadata_group=\"nnpdf31_process\",\n",
    "    theory={\"from_\": \"fit\"},\n",
    "    theoryid={\"from_\": \"theory\"},\n",
    "    pdf={\"from_\": \"fit\"},\n",
    "    datacuts={\"from_\": \"fit\"},\n",
    "    t0pdfset={\"from_\": \"datacuts\"},\n",
    ")\n",
    "\n",
    "settings_dict_ref = dict(\n",
    "    dataset_inputs={\"from_\": \"fit\"},\n",
    "    fit=fit_ref.name,\n",
    "    use_cuts=\"fromfit\",\n",
    "    metadata_group=\"nnpdf31_process\",\n",
    "    theory={\"from_\": \"fit\"},\n",
    "    theoryid={\"from_\": \"theory\"},\n",
    "    pdf={\"from_\": \"fit\"},\n",
    "    datacuts={\"from_\": \"fit\"},\n",
    "    t0pdfset={\"from_\": \"datacuts\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29e4c30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LHAPDF 6.5.4 loading all 501 PDFs in set 240921_01_ht_preds\n",
      "240921_01_ht_preds, version 1; 501 PDF members\n",
      "LHAPDF 6.5.4 loading all 501 PDFs in set 240807-midcuts\n",
      "240807-midcuts, version 1; 501 PDF members\n"
     ]
    }
   ],
   "source": [
    "theorypreds_all = API.group_result_table_no_table(**settings_dict)\n",
    "kinematics_all = API.group_kin_table_no_table(**settings_dict)\n",
    "\n",
    "theorypreds_all_ref = API.group_result_table_no_table(**settings_dict_ref)\n",
    "\n",
    "# Sanity check\n",
    "try:\n",
    "  pd.testing.assert_index_equal(kinematics_all.index, theorypreds_all.index)\n",
    "except AssertionError as e:\n",
    "  print(\"Different index\")\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0333238b",
   "metadata": {},
   "outputs": [],
   "source": [
    "theorypred_reps = theorypreds_all.iloc[:, 2:]\n",
    "theorypdres_mean = theorypred_reps.mean(axis=1)\n",
    "theorypred_rep0 = theorypreds_all.iloc[:, 1]\n",
    "\n",
    "theorypred_reps_ref = theorypreds_all_ref.iloc[:, 2:]\n",
    "theorypdres_mean_ref = theorypred_reps_ref.mean(axis=1)\n",
    "theorypred_rep0_ref = theorypreds_all_ref.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a023f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudodata = API.read_pdf_pseudodata(**settings_dict)\n",
    "data_reps = pd.concat(\n",
    "    [i.pseudodata.reindex(theorypreds_all.index) for i in pseudodata], axis=1\n",
    ")\n",
    "data_reps_mean = data_reps.mean(axis=1)\n",
    "data_exp = theorypreds_all[\"data_central\"]\n",
    "\n",
    "\n",
    "data_exp_ref = theorypreds_all_ref[\"data_central\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac6553b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LHAPDF 6.5.4 loading /opt/homebrew/Caskroom/miniconda/base/envs/nnpdf/share/LHAPDF/210715-n3fit-1000-001/210715-n3fit-1000-001_0000.dat\n",
      "210715-n3fit-1000-001 PDF set, member #0, version 1\n",
      "LHAPDF 6.5.4 loading /opt/homebrew/Caskroom/miniconda/base/envs/nnpdf/share/LHAPDF/210619-n3fit-001/210619-n3fit-001_0000.dat\n",
      "210619-n3fit-001 PDF set, member #0, version 1\n"
     ]
    }
   ],
   "source": [
    "Ct0 = API.groups_covmat(\n",
    "    use_t0=True,\n",
    "    **settings_dict\n",
    ")\n",
    "Cexp = API.groups_covmat(\n",
    "    use_t0=False,\n",
    "    **settings_dict\n",
    ")\n",
    "\n",
    "Ct0_ref = API.groups_covmat(\n",
    "    use_t0=True,\n",
    "    **settings_dict_ref\n",
    ")\n",
    "Cexp_ref = API.groups_covmat(\n",
    "    use_t0=False,\n",
    "    **settings_dict_ref\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3425603",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cinvt0 = np.linalg.inv(Ct0)\n",
    "Cinvexp = np.linalg.inv(Cexp)\n",
    "\n",
    "Cinvt0_ref = np.linalg.inv(Ct0_ref)\n",
    "Cinvexp_ref = np.linalg.inv(Cexp_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d11ff6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ht_theory = pd.Series(data=np.zeros_like(theorypred_rep0.to_numpy()), index=theorypred_rep0.index )\n",
    "ht_theory = pd.DataFrame(ht_theory, columns=['ht'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db8d43f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate kinematics to HT dataframe\n",
    "try:\n",
    "  pd.testing.assert_index_equal(kinematics_all.index, ht_theory.index)\n",
    "  ht_theory = pd.concat([ht_theory, kinematics_all],axis=1)\n",
    "except AssertionError as e:\n",
    "  print(\"Different index\")\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37fd0d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posteriors from 240812-01-ABMP-large-prior-7k\n",
    "x_knots = [0.0, 0.1, 0.3, 0.5, 0.7, 0.9, 1]\n",
    "y_h2_p = [-0.00441, 0.11169, -0.01632, 0.00000, -0.08742, -0.07279, 0.00000]\n",
    "y_hl_p = [0.00000, -0.06241, -0.08655, -0.03306, 0.00000, -0.05987, 0.0000]\n",
    "y_h2_d = [-0.04117, 0.00000, 0.03124, -0.01059, 0.04763, 0.00000, 0.00000]\n",
    "y_hl_d = [0.00316, 0.00469, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]\n",
    "\n",
    "H_2p = scint.CubicSpline(x_knots, y_h2_p)\n",
    "H_lp = scint.CubicSpline(x_knots, y_hl_p)\n",
    "H_2d = scint.CubicSpline(x_knots, y_h2_d)\n",
    "H_ld = scint.CubicSpline(x_knots, y_hl_d)\n",
    "\n",
    "H_2p = np.vectorize(H_2p)\n",
    "H_lp = np.vectorize(H_lp)\n",
    "H_2d = np.vectorize(H_2d)\n",
    "H_ld = np.vectorize(H_ld)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df40f92e",
   "metadata": {},
   "source": [
    "## Compute the HT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d8110f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deactivate performance warning when using df.loc\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "included_proc = ['DIS NC']\n",
    "excluded_exp = {\"DIS NC\" : []}\n",
    "for process_name, process_group in ht_theory.groupby(level='group'):\n",
    "  for exp_name, exp_group in process_group.groupby(level='dataset'):\n",
    "    if process_name in included_proc and exp_name not in excluded_exp[process_name]:\n",
    "      x = exp_group.kin_1.to_numpy()\n",
    "      q2 = exp_group.kin_2.to_numpy()\n",
    "      y = exp_group.kin_3.to_numpy()\n",
    "      N2, NL = compute_normalisation_by_experiment(exp_name, x, y, q2)\n",
    "      if \"_P_\" in exp_name or \"HERA\" in exp_name:\n",
    "        PC_2 = N2 * H_2p(x) / q2\n",
    "        PC_L = NL * H_lp(x) / q2\n",
    "      elif \"_D_\" in exp_name:\n",
    "        PC_2 = N2 * H_2d(x) / q2\n",
    "        PC_L = NL * H_ld(x) / q2\n",
    "      else:\n",
    "        # TODO\n",
    "        # Need to implement this\n",
    "        PC_2 = 0 / q2 #N2 * H_2d(x) / Q2\n",
    "        PC_L = 0 / q2 #NL * H_ld(x) / Q2\n",
    "\n",
    "      ht_theory.loc[(process_name, exp_name), 'ht'] = PC_2 + PC_L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46255893",
   "metadata": {},
   "source": [
    "## Collect process and experiment information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1556d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting name of nnpdf31_processes and experiments\n",
    "process_list = []\n",
    "exp_list = []\n",
    "process_name = ''\n",
    "exp_name = ''\n",
    "for proc in theorypred_rep0.index.to_numpy():\n",
    "  if proc[0] != process_name:\n",
    "    process_name = proc[0]\n",
    "    process_list.append(process_name)\n",
    "\n",
    "  if proc[1] != exp_name:\n",
    "    exp_name = proc[1]\n",
    "    exp_list.append(exp_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cbc380",
   "metadata": {},
   "source": [
    "# Compute global $\\chi^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "794cafc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           name         chi2 w/o HT     chi2 w/ HT\n",
      "         chi2t0         1.3504         1.2869\n",
      " chi2t0_average         1.3757         1.3122\n",
      "   chi2t0_meanT         1.3502         1.2867\n",
      "        chi2exp         1.2809         1.2088\n",
      "           name      Baseline no HT   With HT\n",
      "         chi2t0         1.2648         1.3504\n",
      " chi2t0_average         1.2883         1.3757\n",
      "   chi2t0_meanT         1.2646         1.3502\n",
      "        chi2exp         1.1936         1.2809\n"
     ]
    }
   ],
   "source": [
    "# With HT\n",
    "ndat = theorypred_rep0.size\n",
    "chi2t0 = (theorypred_rep0 +  ht_theory['ht']- data_exp) @ Cinvt0 @ (theorypred_rep0 +  ht_theory['ht'] - data_exp) / ndat\n",
    "chi2t0_average = np.mean([(theorypred_reps[r] +  ht_theory['ht'] - data_exp.to_numpy()) @ Cinvt0 @ (theorypred_reps[r] +  ht_theory['ht'] - data_exp.to_numpy()) for r in theorypred_reps]) / ndat\n",
    "chi2t0_meanT = (theorypred_reps.mean(axis=1) +  ht_theory['ht'] - data_exp) @ Cinvt0 @ (theorypred_reps.mean(axis=1) +  ht_theory['ht'] - data_exp) / ndat\n",
    "chi2exp = (theorypred_rep0 +  ht_theory['ht'] - data_exp) @ Cinvexp @ (theorypred_rep0 +  ht_theory['ht'] - data_exp) / ndat\n",
    "\n",
    "# Without HT\n",
    "chi2t0_no_ht = (theorypred_rep0 - data_exp) @ Cinvt0 @ (theorypred_rep0 - data_exp) / ndat\n",
    "chi2t0_average_no_ht = np.mean([(theorypred_reps[r]  - data_exp.to_numpy()) @ \\\n",
    "                                Cinvt0 @ \\\n",
    "                                (theorypred_reps[r]  - data_exp.to_numpy()) for r in theorypred_reps]) / ndat\n",
    "chi2t0_meanT_no_ht = (theorypred_reps.mean(axis=1)  - data_exp) @ Cinvt0 @ (theorypred_reps.mean(axis=1) - data_exp) / ndat\n",
    "chi2exp_no_ht = (theorypred_rep0  - data_exp) @ Cinvexp @ (theorypred_rep0  - data_exp) / ndat\n",
    "\n",
    "# Reference fit\n",
    "ndat_ref = theorypred_rep0_ref.size\n",
    "chi2t0_ref = (theorypred_rep0_ref - data_exp_ref) @ Cinvt0_ref @ (theorypred_rep0_ref  - data_exp_ref) / ndat_ref\n",
    "chi2t0_average_ref = np.mean([(theorypred_reps_ref[r] - data_exp_ref.to_numpy()) @ Cinvt0_ref @ (theorypred_reps_ref[r] - data_exp_ref.to_numpy()) for r in theorypred_reps_ref]) / ndat_ref\n",
    "chi2t0_meanT_ref = (theorypred_reps_ref.mean(axis=1) - data_exp_ref) @ Cinvt0_ref @ (theorypred_reps_ref.mean(axis=1) - data_exp_ref) / ndat_ref\n",
    "chi2exp_ref = (theorypred_rep0_ref - data_exp_ref) @ Cinvexp_ref @ (theorypred_rep0_ref - data_exp_ref) / ndat_ref\n",
    "\n",
    "\n",
    "if True:\n",
    "  print(f\"{\"name\":>15}{\"chi2 w/o HT\":>20}{\"chi2 w/ HT\":>15}\")\n",
    "  print(f\"{\"chi2t0\":>15}{chi2t0:>15.4f}{chi2t0_no_ht:>15.4f}\")\n",
    "  print(f\"{\"chi2t0_average\":>15}{chi2t0_average:>15.4f}{chi2t0_average_no_ht:>15.4f}\")\n",
    "  print(f\"{\"chi2t0_meanT\":>15}{chi2t0_meanT:>15.4f}{chi2t0_meanT_no_ht:>15.4f}\")\n",
    "  print(f\"{\"chi2exp\":>15}{chi2exp:>15.4f}{chi2exp_no_ht:>15.4f}\")\n",
    "\n",
    "if True:\n",
    "    print(f\"{\"name\":>15}{\"Baseline no HT\":>20}{\"With HT\":>10}\")\n",
    "    print(f\"{\"chi2t0\":>15}{chi2t0_ref:>15.4f}{chi2t0:>15.4f}\")\n",
    "    print(f\"{\"chi2t0_average\":>15}{chi2t0_average_ref:>15.4f}{chi2t0_average:>15.4f}\")\n",
    "    print(f\"{\"chi2t0_meanT\":>15}{chi2t0_meanT_ref:>15.4f}{chi2t0_meanT:>15.4f}\")\n",
    "    print(f\"{\"chi2exp\":>15}{chi2exp_ref:>15.4f}{chi2exp:>15.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa137293",
   "metadata": {},
   "source": [
    "## Compute $\\chi^2$ per process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99f7df21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      name         chi2 w/o HT     chi2 w/ HT\n",
      "    DIS NC         1.2466         1.4022\n",
      "    DIS CC         0.9485         0.9485\n",
      "     DY NC         1.2913         1.2913\n",
      "     DY CC         1.6754         1.6754\n",
      "       TOP         1.1698         1.1698\n",
      "      JETS         1.1660         1.1660\n",
      "     DIJET         2.2998         2.2998\n",
      "    PHOTON         0.8291         0.8291\n",
      " SINGLETOP         0.3477         0.3477\n",
      "           name      Baseline no HT   With HT\n",
      "        DIS NC         1.2492         1.4022\n",
      "        DIS CC         0.9516         0.9485\n",
      "         DY NC         1.2533         1.2913\n",
      "         DY CC         1.6982         1.6754\n",
      "           TOP         1.2836         1.1698\n",
      "          JETS         1.0420         1.1660\n",
      "         DIJET         2.2082         2.2998\n",
      "        PHOTON         0.7839         0.8291\n",
      "     SINGLETOP         0.3566         0.3477\n"
     ]
    }
   ],
   "source": [
    "chi2_dict = {}\n",
    "collector = 0\n",
    "for name in process_list:\n",
    "  theorypred_rep0_PROC = theorypred_rep0.loc[[name]].to_numpy()\n",
    "  data_exp_PROC = data_exp.loc[[name]].to_numpy()\n",
    "\n",
    "  # For reference fit\n",
    "  theorypred_rep0_PROC_ref = theorypred_rep0_ref.loc[[name]].to_numpy()\n",
    "  data_exp_PROC_ref = data_exp_ref.loc[[name]].to_numpy()\n",
    "\n",
    "  ht_PROC = ht_theory.loc[[name], 'ht'].to_numpy()\n",
    "\n",
    "  try:\n",
    "    assert(theorypred_rep0_PROC.shape == data_exp_PROC.shape == ht_PROC.shape)\n",
    "  except AssertionError as e:\n",
    "    print(\"Problem with the shape\")\n",
    "    print(e)\n",
    "\n",
    "  # For reference fit\n",
    "  try:\n",
    "    assert(theorypred_rep0_PROC_ref.shape == data_exp_PROC_ref.shape)\n",
    "  except AssertionError as e:\n",
    "    print(\"Problem with the shape\")\n",
    "    print(e)\n",
    "    \n",
    "  Ndata_PROC = theorypred_rep0_PROC.shape[0]\n",
    "  Cinvexp_PROC = Cinvexp[collector:collector+Ndata_PROC, collector:collector+Ndata_PROC]\n",
    "\n",
    "  # For reference fit\n",
    "  Ndata_PROC_ref = theorypred_rep0_PROC_ref.shape[0]\n",
    "  try:\n",
    "    assert(Ndata_PROC_ref == Ndata_PROC)\n",
    "  except AssertionError as e:\n",
    "    print(\"Fit and reference fit do not have the same number of points\")\n",
    "    print(e)\n",
    "    exit\n",
    "  Cinvexp_PROC_ref = Cinvexp_ref[collector:collector + Ndata_PROC_ref, collector:collector + Ndata_PROC_ref]\n",
    "\n",
    "  collector += Ndata_PROC\n",
    "\n",
    "  chi2exp_PROC = (theorypred_rep0_PROC +  ht_PROC - data_exp_PROC) @ Cinvexp_PROC @ (theorypred_rep0_PROC +  ht_PROC - data_exp_PROC) / Ndata_PROC\n",
    "  chi2exp_no_ht_PROC = (theorypred_rep0_PROC - data_exp_PROC) @ Cinvexp_PROC @ (theorypred_rep0_PROC - data_exp_PROC) / Ndata_PROC\n",
    "\n",
    "  # For reference fit\n",
    "  chi2exp_PROC_ref = (theorypred_rep0_PROC_ref - data_exp_PROC_ref) @ Cinvexp_PROC_ref @ (theorypred_rep0_PROC_ref - data_exp_PROC_ref) / Ndata_PROC_ref\n",
    "\n",
    "  chi2_dict[name] = {\"HT\": chi2exp_PROC, \"NO_HT\": chi2exp_no_ht_PROC, \"ref\": chi2exp_PROC_ref}\n",
    "\n",
    "if True:\n",
    "  print(f\"{\"name\":>10}{\"chi2 w/o HT\":>20}{\"chi2 w/ HT\":>15}\")\n",
    "  for name in chi2_dict.keys():\n",
    "    print(f\"{name:>10}{chi2_dict[name][\"NO_HT\"]:>15.4f}{chi2_dict[name][\"HT\"]:>15.4f}\")\n",
    "\n",
    "if True:\n",
    "  print(f\"{\"name\":>15}{\"Baseline no HT\":>20}{\"With HT\":>10}\")\n",
    "  for name in chi2_dict.keys():\n",
    "    print(f\"{name:>14}{chi2_dict[name][\"ref\"]:>15.4f}{chi2_dict[name][\"HT\"]:>15.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea44ba47",
   "metadata": {},
   "source": [
    "## Compute $\\chi^2$ per experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49d42e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          name                   chi2 w/o HT     chi2 w/ HT\n",
      "                NMC_NC_NOTFIXED_DW_EM-F2         0.8828         0.8828\n",
      "           NMC_NC_NOTFIXED_P_EM-SIGMARED         1.6665         1.8899\n",
      "             SLAC_NC_NOTFIXED_P_DW_EM-F2         0.9829         2.8635\n",
      "             SLAC_NC_NOTFIXED_D_DW_EM-F2         0.7522         1.1665\n",
      "            BCDMS_NC_NOTFIXED_P_DW_EM-F2         1.5464         1.6274\n",
      "            BCDMS_NC_NOTFIXED_D_DW_EM-F2         1.3437         1.4423\n",
      "              HERA_NC_318GEV_EM-SIGMARED         1.5484         1.5462\n",
      "              HERA_NC_225GEV_EP-SIGMARED         1.4122         1.4118\n",
      "              HERA_NC_251GEV_EP-SIGMARED         1.2017         1.2022\n",
      "              HERA_NC_300GEV_EP-SIGMARED         1.6596         1.6726\n",
      "              HERA_NC_318GEV_EP-SIGMARED         1.4737         1.4570\n",
      "      HERA_NC_318GEV_EAVG_CHARM-SIGMARED         1.9972         1.9932\n",
      "     HERA_NC_318GEV_EAVG_BOTTOM-SIGMARED         1.4602         1.6043\n",
      "                                    name      Baseline no HT   With HT\n",
      "                NMC_NC_NOTFIXED_DW_EM-F2         0.8770         0.8828\n",
      "           NMC_NC_NOTFIXED_P_EM-SIGMARED         1.5986         1.8899\n",
      "             SLAC_NC_NOTFIXED_P_DW_EM-F2         0.9858         2.8635\n",
      "             SLAC_NC_NOTFIXED_D_DW_EM-F2         0.7213         1.1665\n",
      "            BCDMS_NC_NOTFIXED_P_DW_EM-F2         1.5370         1.6274\n",
      "            BCDMS_NC_NOTFIXED_D_DW_EM-F2         1.3855         1.4423\n",
      "              HERA_NC_318GEV_EM-SIGMARED         1.4610         1.5462\n",
      "              HERA_NC_225GEV_EP-SIGMARED         1.3597         1.4118\n",
      "              HERA_NC_251GEV_EP-SIGMARED         1.1559         1.2022\n",
      "              HERA_NC_300GEV_EP-SIGMARED         1.5548         1.6726\n",
      "              HERA_NC_318GEV_EP-SIGMARED         1.3902         1.4570\n",
      "      HERA_NC_318GEV_EAVG_CHARM-SIGMARED         2.0548         1.9932\n",
      "     HERA_NC_318GEV_EAVG_BOTTOM-SIGMARED         1.4419         1.6043\n"
     ]
    }
   ],
   "source": [
    "chi2_dict_exp = {}\n",
    "collector = 0\n",
    "for name in exp_list:\n",
    "  theorypred_rep0_exp = theorypred_rep0.xs(name, level=\"dataset\").to_numpy()\n",
    "  data_exp_exp = data_exp.xs(name, level=\"dataset\").to_numpy()\n",
    "  ht_exp = ht_theory.xs(name, level='dataset')['ht'].to_numpy()\n",
    "  try:\n",
    "    assert(theorypred_rep0_exp.shape == ht_exp.shape == data_exp_exp.shape)\n",
    "  except AssertionError as e:\n",
    "    print(\"Problem with the shape\")\n",
    "    print(e)\n",
    "\n",
    "  # For reference fit\n",
    "  theorypred_rep0_exp_ref = theorypred_rep0_ref.xs(name, level=\"dataset\").to_numpy()\n",
    "  data_exp_exp_ref = data_exp_ref.xs(name, level=\"dataset\").to_numpy()\n",
    "    \n",
    "  ndata_exp = theorypred_rep0_exp.shape[0]\n",
    "  Cinvexp_exp = Cinvexp[collector:collector + ndata_exp, collector:collector + ndata_exp]\n",
    "\n",
    "  # For reference fit\n",
    "  ndata_exp_ref = theorypred_rep0_exp_ref.shape[0]\n",
    "  Cinvexp_exp_ref = Cinvexp_ref[collector:collector + ndata_exp_ref, collector:collector + ndata_exp_ref]\n",
    "\n",
    "  collector += ndata_exp\n",
    "\n",
    "  chi2exp_exp = (theorypred_rep0_exp +  ht_exp - data_exp_exp) @ Cinvexp_exp @ (theorypred_rep0_exp +  ht_exp - data_exp_exp) / ndata_exp\n",
    "  chi2exp_no_ht_exp = (theorypred_rep0_exp - data_exp_exp) @ Cinvexp_exp @ (theorypred_rep0_exp - data_exp_exp) / ndata_exp\n",
    "\n",
    "  chi2exp_no_ht_exp_ref = (theorypred_rep0_exp_ref - data_exp_exp_ref) @ Cinvexp_exp_ref @ (theorypred_rep0_exp_ref - data_exp_exp_ref) / ndata_exp_ref\n",
    "\n",
    "  chi2_dict_exp[name] = {\"HT\": chi2exp_exp, \n",
    "                         \"NO_HT\": chi2exp_no_ht_exp, \n",
    "                         \"ref\": chi2exp_no_ht_exp_ref,\n",
    "                         \"show\": True if ht_theory.xs(name, level='dataset')['ht'].index[0][0] == 'DIS NC' else False}\n",
    "\n",
    "if True:\n",
    "  print(f\"{\"name\":>30}{\"chi2 w/o HT\":>30}{\"chi2 w/ HT\":>15}\")\n",
    "  for name in chi2_dict_exp.keys():\n",
    "    if chi2_dict_exp[name]['show']:\n",
    "      print(f\"{name:>40}{chi2_dict_exp[name][\"NO_HT\"]:>15.4f}{chi2_dict_exp[name][\"HT\"]:>15.4f}\")\n",
    "\n",
    "if True:\n",
    "  print(f\"{\"name\":>40}{\"Baseline no HT\":>20}{\"With HT\":>10}\")\n",
    "  for name in chi2_dict_exp.keys():\n",
    "    if chi2_dict_exp[name]['show']:\n",
    "      print(f\"{name:>40}{chi2_dict_exp[name][\"ref\"]:>15.4f}{chi2_dict_exp[name][\"HT\"]:>15.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc8ed95",
   "metadata": {},
   "source": [
    "# Compute pseudodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b7df35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2t0_pseudodata = (theorypred_rep0 - data_reps_mean) @ Cinvt0 @ (theorypred_rep0 - data_reps_mean) / ndat\n",
    "chi2t0_average_pseudodata = np.mean([(theorypred_reps[r] - data_reps_mean.to_numpy()) @ Cinvt0 @ (theorypred_reps[r] - data_reps_mean.to_numpy()) for r in theorypred_reps]) / ndat\n",
    "chi2t0_meanT_pseudodata = (theorypred_reps.mean(axis=1) - data_reps_mean) @ Cinvt0 @ (theorypred_reps.mean(axis=1) - data_reps_mean) / ndat\n",
    "chi2exp_pseudodata = (theorypred_rep0 - data_reps_mean) @ Cinvexp @ (theorypred_rep0 - data_reps_mean) / ndat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "589e3134e9d89160e5ace28972e8dc0b682f48816407b59cbfdad217f6fb745b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
